{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02743ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "279c633d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package names to /Users/quratul-\n",
      "[nltk_data]     ainmahesar/nltk_data...\n",
      "[nltk_data]   Package names is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /Users/quratul-\n",
      "[nltk_data]     ainmahesar/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package state_union to /Users/quratul-\n",
      "[nltk_data]     ainmahesar/nltk_data...\n",
      "[nltk_data]   Package state_union is already up-to-date!\n",
      "[nltk_data] Downloading package twitter_samples to /Users/quratul-\n",
      "[nltk_data]     ainmahesar/nltk_data...\n",
      "[nltk_data]   Package twitter_samples is already up-to-date!\n",
      "[nltk_data] Downloading package movie_reviews to /Users/quratul-\n",
      "[nltk_data]     ainmahesar/nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/quratul-ainmahesar/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package vader_lexicon to /Users/quratul-\n",
      "[nltk_data]     ainmahesar/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/quratul-\n",
      "[nltk_data]     ainmahesar/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download([\"names\",\"stopwords\",\"state_union\",\"twitter_samples\",\"movie_reviews\",\"averaged_perceptron_tagger\",\"vader_lexicon\",\"punkt\",])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ca33a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e40eb1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sia = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cfdb7a0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 0.295, 'pos': 0.705, 'compound': 0.8012}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sia.polarity_scores(\"Wow, NLTK is really powerful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5497a59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = [t.replace(\"://\", \"//\") for t in nltk.corpus.twitter_samples.strings()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1200130d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> False RT @SkyNews: Why won't David Cameron debate with Ed Miliband directly? #GE2015  http//t.co/n5H9t7LmuO\n",
      "> True @davidc79 thx! And Android support in by Xmas :)\n",
      "> True @adnanCad Planted people are allowed to do any thing and every thing :p\n",
      "> True RT @MartinSLewis: Miliband has grown in presentational confidence enormously - he had more humour and warmth than Cameron. #bbcqt\n",
      "> False @bellacaledonia trouble is, Ed didnt call it a \"Vow\" to never work with Snp because (as we all know) that would be meaningless &amp; breakable\n",
      "> False RT @ShropshireStar: Now Ukip member’s campaign posters defaced in #Ludlow campaign http//t.co/uoigIaikK2 http//t.co/fP51GOPF0v\n",
      "> True why does everyone like my voice i sound like ed miliband choking on sandwich\n",
      "> False @MrsPiszczek nein :(\n",
      "> True RT @NicolaSturgeon: If Miliband is going to let Tories in rather than work with SNP, we will definitely need lots of SNP MPs to protect Sco…\n",
      "> False VIDEO: 'I will never apologise' for coalition: Lib Dem leader Nick Clegg has defended his decision to go into ... http//t.co/nnUyhfmko6\n"
     ]
    }
   ],
   "source": [
    "from random import shuffle\n",
    "\n",
    "def is_positive(tweet: str) -> bool:\n",
    "    \"\"\"True if tweet has positive compound sentiment, False otherwise.\"\"\"\n",
    "    return sia.polarity_scores(tweet)[\"compound\"] > 0\n",
    "\n",
    "shuffle(tweets)\n",
    "for tweet in tweets[:10]:\n",
    "    print(\">\", is_positive(tweet), tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "333c7453",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_review_ids = nltk.corpus.movie_reviews.fileids(categories=[\"pos\"])\n",
    "negative_review_ids = nltk.corpus.movie_reviews.fileids(categories=[\"neg\"])\n",
    "all_review_ids = positive_review_ids + negative_review_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c7e95326",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mean\n",
    "\n",
    "def is_positive(review_id: str) -> bool:\n",
    "    \"\"\"True if the average of all sentence compound scores is positive.\"\"\"\n",
    "    text = nltk.corpus.movie_reviews.raw(review_id)\n",
    "    scores = [\n",
    "        sia.polarity_scores(sentence)[\"compound\"]\n",
    "        for sentence in nltk.sent_tokenize(text)\n",
    "    ]\n",
    "    return mean(scores) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "41a81a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69.10% correct\n"
     ]
    }
   ],
   "source": [
    "shuffle(all_review_ids)\n",
    "correct = 0\n",
    "for review_id in all_review_ids:\n",
    "     if is_positive(review_id):\n",
    "        if review_id in positive_review_ids:\n",
    "            correct += 1\n",
    "        else:\n",
    "             if review_id in negative_review_ids:\n",
    "                correct += 1\n",
    "\n",
    "print(F\"{correct / len(all_review_ids):.2%} correct\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "10f1e3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "unwanted = nltk.corpus.stopwords.words(\"english\")\n",
    "\n",
    "unwanted.extend([w.lower() for w in nltk.corpus.names.words()])\n",
    "\n",
    "\n",
    "def skip_unwanted(pos_tuple):\n",
    "\n",
    "    word, tag = pos_tuple\n",
    "\n",
    "    if not word.isalpha() or word in unwanted:\n",
    "\n",
    "        return False\n",
    "\n",
    "    if tag.startswith(\"NN\"):\n",
    "\n",
    "        return False\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "positive_words = [word for word, tag in filter(\n",
    "\n",
    "    skip_unwanted,\n",
    "\n",
    "    nltk.pos_tag(nltk.corpus.movie_reviews.words(categories=[\"pos\"]))\n",
    "\n",
    ")]\n",
    "\n",
    "negative_words = [word for word, tag in filter(\n",
    "\n",
    "    skip_unwanted,\n",
    "\n",
    "    nltk.pos_tag(nltk.corpus.movie_reviews.words(categories=[\"neg\"]))\n",
    "\n",
    ")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "331fe9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_fd = nltk.FreqDist(positive_words)\n",
    "negative_fd = nltk.FreqDist(negative_words)\n",
    "\n",
    "common_set = set(positive_fd).intersection(negative_fd)\n",
    "\n",
    "for word in common_set:\n",
    "    del positive_fd[word]\n",
    "    del negative_fd[word]\n",
    "\n",
    "top_100_positive = {word for word, count in positive_fd.most_common(100)}\n",
    "top_100_negative = {word for word, count in negative_fd.most_common(100)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e270fb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(text):\n",
    "    features = dict()\n",
    "    wordcount = 0\n",
    "    compound_scores = list()\n",
    "    positive_scores = list()\n",
    "\n",
    "    for sentence in nltk.sent_tokenize(text):\n",
    "        for word in nltk.word_tokenize(sentence):\n",
    "            if word.lower() in top_100_positive:\n",
    "                wordcount += 1\n",
    "        compound_scores.append(sia.polarity_scores(sentence)[\"compound\"])\n",
    "        positive_scores.append(sia.polarity_scores(sentence)[\"pos\"])\n",
    "\n",
    "    # Adding 1 to the final compound score to always have positive numbers\n",
    "    # since some classifiers you'll use later don't work with negative numbers.\n",
    "    features[\"mean_compound\"] = mean(compound_scores) + 1\n",
    "    features[\"mean_positive\"] = mean(positive_scores)\n",
    "    features[\"wordcount\"] = wordcount\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4c1d6371",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    (extract_features(nltk.corpus.movie_reviews.raw(review)), \"pos\")\n",
    "    for review in nltk.corpus.movie_reviews.fileids(categories=[\"pos\"])\n",
    "]\n",
    "features.extend([\n",
    "    (extract_features(nltk.corpus.movie_reviews.raw(review)), \"neg\")\n",
    "    for review in nltk.corpus.movie_reviews.fileids(categories=[\"neg\"])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ca1a8885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "               wordcount = 3                 pos : neg    =      6.7 : 1.0\n",
      "               wordcount = 2                 pos : neg    =      3.5 : 1.0\n",
      "               wordcount = 0                 neg : pos    =      1.5 : 1.0\n",
      "               wordcount = 1                 pos : neg    =      1.1 : 1.0\n",
      "               wordcount = 4                 pos : neg    =      1.1 : 1.0\n",
      "           mean_positive = 0.10585714285714286    pos : neg    =      1.0 : 1.0\n",
      "           mean_positive = 0.12558333333333332    pos : neg    =      1.0 : 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6753333333333333"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_count = len(features) // 4\n",
    "shuffle(features)\n",
    "classifier = nltk.NaiveBayesClassifier.train(features[:train_count])\n",
    "classifier.show_most_informative_features(10)\n",
    "nltk.classify.accuracy(classifier, features[train_count:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a413baf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
